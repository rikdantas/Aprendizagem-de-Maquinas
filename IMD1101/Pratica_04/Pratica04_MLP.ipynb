{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPhoH+XTFs3Chgs1SPTtcjo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rikdantas/Aprendizagem-de-Maquinas/blob/main/IMD1101/Pratica_04/Pratica04_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prática 04 - Técnica Supervisionada (MLP)\n",
        "Nesse notebook será aplicado o método de MLP nas 6 melhores bases que eu tinha encontrado na prática 01 e também nas 6 bases que foram aplicados o PCA também na prática 01.\n",
        "\n",
        "Aluno: Paulo Ricardo Dantas"
      ],
      "metadata": {
        "id": "R8OzpZh4D2ca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f6IddCwYDxOY"
      },
      "outputs": [],
      "source": [
        "# Importando as bibliotecas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gdown\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baixando os datasets"
      ],
      "metadata": {
        "id": "Jzs45cqxES8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando função para baixar os datasets, assim deixando o código um pouco mais organizado\n",
        "def baixar_dataset(url, output):\n",
        "    gdown.download(url, output, quiet=True)"
      ],
      "metadata": {
        "id": "RC_j1NM7EcSD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando datasets do VGG16\n",
        "baixar_dataset('https://drive.google.com/uc?id=1Lig0-UqpGvMQCmV5r5U__yucoocrlbtf', 'VGG16_1.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=1V7_N11eqBnTiM9iKY3vhMVrTzoERrijS', 'VGG16_2.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=1d8spY-o4xBsozdeSbGGlweZrips1m0HC', 'VGG16_3.csv')\n",
        "\n",
        "# Baixando datasets do VGG19\n",
        "baixar_dataset('https://drive.google.com/uc?id=1yjuqQKxXtBqlMetGgD3fyFjDZ3zg3YDS', 'VGG19_1.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=13nmb2kPrv6oVKlhodM-_ierzsMrvWL18', 'VGG19_2.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=1qB2SQXLtgS01FqTrwGYLdOY1pwRqkuXu', 'VGG19_3.csv')\n",
        "\n",
        "# Baixando datasets do PCA\n",
        "baixar_dataset('https://drive.google.com/uc?id=14sGLGGak-1WZwnLrqEMEZbYWNZL1dIVn', 'PCA_1.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=1DCXErsoiqwcM59QkIOdlZcIVGZDmWYTK', 'PCA_2.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=15k9bMm1ZfliNeHQ6MX7SlEy49UQJrxtv', 'PCA_3.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=17BJNdaH_8fCYTJn-l-QH7ayRaLuWYxQ6', 'PCA_4.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=18_qRzZ4wA-laBL0bsCch6xTus7SYLjLf', 'PCA_5.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=1mc9uT_EDkh9xC8rWnZTUZp6qX8Q7verz', 'PCA_6.csv')"
      ],
      "metadata": {
        "id": "Kl-EOeT0EdZU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando os datasets\n",
        "Vamos usar o pandas para importar os datasets para DataFrames. Usaremos os mesmos nomes que foram baixados os arquivos dos datasets. Podemos relacionar os datasets com as configurações como visto na tabela a seguir:\n",
        "\n",
        "| Nome do dataset | Configuração            |\n",
        "|-----------------|-------------------------|\n",
        "| VGG16_1         | CNN_VGG16_128_avg       |\n",
        "| VGG16_2         | CNN_VGG16_128_max       |\n",
        "| VGG16_3         | CNN_VGG16_256_avg       |\n",
        "| VGG19_1         | CNN_VGG19_128_avg       |\n",
        "| VGG19_2         | CNN_VGG19_128_max       |\n",
        "| VGG19_3         | CNN_VGG19_256_avg       |\n",
        "| PCA_1           | PCA_CNN_VGG16_128_avg   |\n",
        "| PCA_2           | PCA_CNN_VGG16_128_max   |\n",
        "| PCA_3           | PCA_CNN_VGG16_256_avg   |\n",
        "| PCA_4           | PCA_CNN_VGG19_128_avg   |\n",
        "| PCA_5           | PCA_CNN_VGG19_128_max   |\n",
        "| PCA_6           | PCA_CNN_VGG19_256_avg   |\n"
      ],
      "metadata": {
        "id": "TTIWX6PSEq6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando os datasets do VGG16\n",
        "vgg16_1 = pd.read_csv('VGG16_1.csv', encoding='utf-8')\n",
        "vgg16_2 = pd.read_csv('VGG16_2.csv', encoding='utf-8')\n",
        "vgg16_3 = pd.read_csv('VGG16_3.csv', encoding='utf-8')\n",
        "\n",
        "# Importando os datasets do VGG19\n",
        "vgg19_1 = pd.read_csv('VGG19_1.csv', encoding='utf-8')\n",
        "vgg19_2 = pd.read_csv('VGG19_2.csv', encoding='utf-8')\n",
        "vgg19_3 = pd.read_csv('VGG19_3.csv', encoding='utf-8')\n",
        "\n",
        "# Importando os datasets do PCA\n",
        "pca_1 = pd.read_csv('PCA_1.csv', encoding='utf-8')\n",
        "pca_2 = pd.read_csv('PCA_2.csv', encoding='utf-8')\n",
        "pca_3 = pd.read_csv('PCA_3.csv', encoding='utf-8')\n",
        "pca_4 = pd.read_csv('PCA_4.csv', encoding='utf-8')\n",
        "pca_5 = pd.read_csv('PCA_5.csv', encoding='utf-8')\n",
        "pca_6 = pd.read_csv('PCA_6.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "D-VwpANkEx-C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicando o MLP"
      ],
      "metadata": {
        "id": "NYRN0H9uwiK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando o holdout"
      ],
      "metadata": {
        "id": "eETMop73wmk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista dos datasets\n",
        "vgg_datasets = [vgg16_1, vgg16_2, vgg16_3, vgg19_1, vgg19_2, vgg19_3]\n",
        "pca_datasets = [pca_1, pca_2, pca_3, pca_4, pca_5, pca_6]\n",
        "\n",
        "# Parâmetros\n",
        "hidden_vgg = 256\n",
        "hidden_pca = 6\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "iterations = [500, 1000, 1500]\n",
        "\n",
        "# DataFrame para armazenar os resultados\n",
        "results = []"
      ],
      "metadata": {
        "id": "SYPOIhalwpQe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Criando função para auxiliar na organização do código"
      ],
      "metadata": {
        "id": "It60_sY1gwGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para rodar experimentos\n",
        "def run_experiment(datasets, hidden_neurons, dataset_type):\n",
        "    for i, dataset in enumerate(datasets):\n",
        "        X = dataset.iloc[:, :-1]\n",
        "        y = dataset['class']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "        for lr in learning_rates:\n",
        "            for iters in iterations:\n",
        "                # Configurando o MLP\n",
        "                mlp = MLPClassifier(\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    hidden_layer_sizes=(hidden_neurons,),\n",
        "                    learning_rate_init=lr,\n",
        "                    max_iter=iters,\n",
        "                    random_state=1\n",
        "                )\n",
        "                # Treinando e avaliando\n",
        "                mlp.fit(X_train, y_train)\n",
        "                y_pred = mlp.predict(X_test)\n",
        "                acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "                # Armazenando o resultado\n",
        "                results.append({\n",
        "                    'Dataset': f\"{dataset_type}_{i+1}\",\n",
        "                    'Hidden Neurons': hidden_neurons,\n",
        "                    'Learning Rate': lr,\n",
        "                    'Iterations': iters,\n",
        "                    'Accuracy': acc\n",
        "                })"
      ],
      "metadata": {
        "id": "H763XAoAw4o_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rodando os experimentos"
      ],
      "metadata": {
        "id": "ZfAy7_9mhS90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rodando os experimentos para VGG e PCA\n",
        "run_experiment(vgg_datasets, hidden_vgg, \"VGG\")\n",
        "run_experiment(pca_datasets, hidden_pca, \"PCA\")\n",
        "\n",
        "# Convertendo resultados em DataFrame\n",
        "results_holdout = pd.DataFrame(results)\n",
        "\n",
        "# Salvando os resultados em CSV\n",
        "results_holdout.to_csv('Resultados_MLP_Holdout.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHSLnml0hU4p",
        "outputId": "8a6416ab-49ea-4321-e9f8-8201f60f8522"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando K-Fold"
      ],
      "metadata": {
        "id": "BFjRGrMuyWtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista dos datasets\n",
        "vgg_datasets = [vgg16_1, vgg16_2, vgg16_3, vgg19_1, vgg19_2, vgg19_3]\n",
        "pca_datasets = [pca_1, pca_2, pca_3, pca_4, pca_5, pca_6]\n",
        "\n",
        "# Parâmetros\n",
        "hidden_vgg = 256\n",
        "hidden_pca = 6\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "iterations = [500, 1000, 1500]\n",
        "\n",
        "# DataFrame para armazenar os resultados\n",
        "results_kfold = []"
      ],
      "metadata": {
        "id": "77iXTSKG0I6i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Criando função para auxiliar na organização do código"
      ],
      "metadata": {
        "id": "14qig82sjIyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para rodar experimentos com validação cruzada\n",
        "def run_experiment_cv(datasets, hidden_neurons, dataset_type):\n",
        "    for i, dataset in enumerate(datasets):\n",
        "        X = dataset.iloc[:, :-1]\n",
        "        y = dataset['class']\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "        for lr in learning_rates:\n",
        "            for iters in iterations:\n",
        "                # Configurando o MLP\n",
        "                mlp = MLPClassifier(\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    hidden_layer_sizes=(hidden_neurons,),\n",
        "                    learning_rate_init=lr,\n",
        "                    max_iter=iters,\n",
        "                    random_state=1\n",
        "                )\n",
        "                # Executando 10-fold CV\n",
        "                scores = cross_val_score(mlp, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "                # Armazenando o resultado\n",
        "                results_kfold.append({\n",
        "                    'Dataset': f\"{dataset_type}_{i+1}\",\n",
        "                    'Hidden Neurons': hidden_neurons,\n",
        "                    'Learning Rate': lr,\n",
        "                    'Iterations': iters,\n",
        "                    'Mean Accuracy': np.mean(scores),\n",
        "                    'Std Dev Accuracy': np.std(scores)\n",
        "                })"
      ],
      "metadata": {
        "id": "hbHsomSCjH_L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rodando os experimentos"
      ],
      "metadata": {
        "id": "TkttoAYbjbQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rodando os experimentos para VGG e PCA\n",
        "run_experiment_cv(vgg_datasets, hidden_vgg, \"VGG\")\n",
        "run_experiment_cv(pca_datasets, hidden_pca, \"PCA\")\n",
        "\n",
        "# Convertendo resultados em DataFrame\n",
        "results_kfold_df = pd.DataFrame(results_kfold)\n",
        "\n",
        "# Salvando os resultados em CSV\n",
        "results_kfold_df.to_csv('Resultados_MLP_KFold.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70vUnWk_0b62",
        "outputId": "87216288-7397-4bb8-a672-f0cfd5d042f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}