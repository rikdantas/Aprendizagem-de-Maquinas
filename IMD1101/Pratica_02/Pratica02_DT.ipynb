{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaK9BlvXf1ybRoweTnEQsD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rikdantas/Aprendizagem-de-Maquinas/blob/main/IMD1101/Pratica_02/Pratica02_DT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prática 02 - Técnica Supervisionada (DT)\n",
        "Nesse notebook será aplicado o método de árvore de decisão nas 6 melhores bases que eu tinha encontrado na prática 01 e também nas 6 bases que foram aplicados o PCA também na prática 01.\n",
        "\n",
        "Aluno: Paulo Ricardo Dantas"
      ],
      "metadata": {
        "id": "R8OzpZh4D2ca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f6IddCwYDxOY"
      },
      "outputs": [],
      "source": [
        "# Importando as bibliotecas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gdown\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baixando os datasets"
      ],
      "metadata": {
        "id": "Jzs45cqxES8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando função para baixar os datasets, assim deixando o código um pouco mais organizado\n",
        "def baixar_dataset(url, output):\n",
        "    gdown.download(url, output, quiet=True)"
      ],
      "metadata": {
        "id": "RC_j1NM7EcSD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando datasets do VGG16\n",
        "baixar_dataset('https://drive.google.com/uc?id=1Lig0-UqpGvMQCmV5r5U__yucoocrlbtf', 'VGG16_1.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=1V7_N11eqBnTiM9iKY3vhMVrTzoERrijS', 'VGG16_2.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=1d8spY-o4xBsozdeSbGGlweZrips1m0HC', 'VGG16_3.csv')\n",
        "\n",
        "# Baixando datasets do VGG19\n",
        "baixar_dataset('https://drive.google.com/uc?id=1yjuqQKxXtBqlMetGgD3fyFjDZ3zg3YDS', 'VGG19_1.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=13nmb2kPrv6oVKlhodM-_ierzsMrvWL18', 'VGG19_2.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=1qB2SQXLtgS01FqTrwGYLdOY1pwRqkuXu', 'VGG19_3.csv')\n",
        "\n",
        "# Baixando datasets do PCA\n",
        "baixar_dataset('https://drive.google.com/uc?id=14sGLGGak-1WZwnLrqEMEZbYWNZL1dIVn', 'PCA_1.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=1DCXErsoiqwcM59QkIOdlZcIVGZDmWYTK', 'PCA_2.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=15k9bMm1ZfliNeHQ6MX7SlEy49UQJrxtv', 'PCA_3.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=17BJNdaH_8fCYTJn-l-QH7ayRaLuWYxQ6', 'PCA_4.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=18_qRzZ4wA-laBL0bsCch6xTus7SYLjLf', 'PCA_5.csv')\n",
        "baixar_dataset('https://drive.google.com/uc?id=1mc9uT_EDkh9xC8rWnZTUZp6qX8Q7verz', 'PCA_6.csv')"
      ],
      "metadata": {
        "id": "Kl-EOeT0EdZU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando os datasets\n",
        "Vamos usar o pandas para importar os datasets para DataFrames. Usaremos os mesmos nomes que foram baixados os arquivos dos datasets. Podemos relacionar os datasets com as configurações como visto na tabela a seguir:\n",
        "\n",
        "| Nome do dataset | Configuração            |\n",
        "|-----------------|-------------------------|\n",
        "| VGG16_1         | CNN_VGG16_128_avg       |\n",
        "| VGG16_2         | CNN_VGG16_128_max       |\n",
        "| VGG16_3         | CNN_VGG16_256_avg       |\n",
        "| VGG19_1         | CNN_VGG19_128_avg       |\n",
        "| VGG19_2         | CNN_VGG19_128_max       |\n",
        "| VGG19_3         | CNN_VGG19_256_avg       |\n",
        "| PCA_1           | PCA_CNN_VGG16_128_avg   |\n",
        "| PCA_2           | PCA_CNN_VGG16_128_max   |\n",
        "| PCA_3           | PCA_CNN_VGG16_256_avg   |\n",
        "| PCA_4           | PCA_CNN_VGG19_128_avg   |\n",
        "| PCA_5           | PCA_CNN_VGG19_128_max   |\n",
        "| PCA_6           | PCA_CNN_VGG19_256_avg   |\n"
      ],
      "metadata": {
        "id": "TTIWX6PSEq6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando os datasets do VGG16\n",
        "vgg16_1 = pd.read_csv('VGG16_1.csv', encoding='utf-8')\n",
        "vgg16_2 = pd.read_csv('VGG16_2.csv', encoding='utf-8')\n",
        "vgg16_3 = pd.read_csv('VGG16_3.csv', encoding='utf-8')\n",
        "\n",
        "# Importando os datasets do VGG19\n",
        "vgg19_1 = pd.read_csv('VGG19_1.csv', encoding='utf-8')\n",
        "vgg19_2 = pd.read_csv('VGG19_2.csv', encoding='utf-8')\n",
        "vgg19_3 = pd.read_csv('VGG19_3.csv', encoding='utf-8')\n",
        "\n",
        "# Importando os datasets do PCA\n",
        "pca_1 = pd.read_csv('PCA_1.csv', encoding='utf-8')\n",
        "pca_2 = pd.read_csv('PCA_2.csv', encoding='utf-8')\n",
        "pca_3 = pd.read_csv('PCA_3.csv', encoding='utf-8')\n",
        "pca_4 = pd.read_csv('PCA_4.csv', encoding='utf-8')\n",
        "pca_5 = pd.read_csv('PCA_5.csv', encoding='utf-8')\n",
        "pca_6 = pd.read_csv('PCA_6.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "D-VwpANkEx-C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicando a DecisionTree\n"
      ],
      "metadata": {
        "id": "my8ZBAkKINam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando holdout\n"
      ],
      "metadata": {
        "id": "6fGBZWppIRog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista dos datasets\n",
        "datasets = {\n",
        "    \"vgg16_1\": vgg16_1,\n",
        "    \"vgg16_2\": vgg16_2,\n",
        "    \"vgg16_3\": vgg16_3,\n",
        "    \"vgg19_1\": vgg19_1,\n",
        "    \"vgg19_2\": vgg19_2,\n",
        "    \"vgg19_3\": vgg19_3,\n",
        "    \"pca_1\": pca_1,\n",
        "    \"pca_2\": pca_2,\n",
        "    \"pca_3\": pca_3,\n",
        "    \"pca_4\": pca_4,\n",
        "    \"pca_5\": pca_5,\n",
        "    \"pca_6\": pca_6\n",
        "}\n",
        "\n",
        "results = []"
      ],
      "metadata": {
        "id": "EkfeOePIJKo1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop pelos datasets\n",
        "for name, data in datasets.items():\n",
        "    # Separando atributos e rótulos\n",
        "    X = data.iloc[:, :-1]\n",
        "    y = data.iloc[:, -1]\n",
        "\n",
        "    # Dividindo em treino e teste (70/30)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "    # Testando diferentes valores de max_depth\n",
        "    for max_depth in range(2, 11):\n",
        "        # Criando e treinando o modelo\n",
        "        model = DecisionTreeClassifier(max_depth=max_depth, random_state=1)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Prevendo no conjunto de teste\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculando a acurácia\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Salvando os resultados\n",
        "        results.append({\"Dataset\": name, \"Max Depth\": max_depth, \"Accuracy\": acc})\n",
        "\n",
        "# Convertendo os resultados para DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Salvando os resultados em um CSV\n",
        "results_df.to_csv(\"Resultados_Decision_Tree_Holdout.csv\", index=False)\n",
        "\n",
        "# Exibindo os resultados\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjkCRG1mJ0yx",
        "outputId": "ce40968a-9af5-46cc-a0b9-ce69bd209702"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Dataset  Max Depth  Accuracy\n",
            "0    vgg16_1          2  0.654167\n",
            "1    vgg16_1          3  0.700000\n",
            "2    vgg16_1          4  0.691667\n",
            "3    vgg16_1          5  0.687500\n",
            "4    vgg16_1          6  0.679167\n",
            "..       ...        ...       ...\n",
            "103    pca_6          6  0.637500\n",
            "104    pca_6          7  0.645833\n",
            "105    pca_6          8  0.633333\n",
            "106    pca_6          9  0.633333\n",
            "107    pca_6         10  0.650000\n",
            "\n",
            "[108 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando K-fold\n"
      ],
      "metadata": {
        "id": "yql3oPJtKBuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista dos datasets\n",
        "datasets = {\n",
        "    \"vgg16_1\": vgg16_1,\n",
        "    \"vgg16_2\": vgg16_2,\n",
        "    \"vgg16_3\": vgg16_3,\n",
        "    \"vgg19_1\": vgg19_1,\n",
        "    \"vgg19_2\": vgg19_2,\n",
        "    \"vgg19_3\": vgg19_3,\n",
        "    \"pca_1\": pca_1,\n",
        "    \"pca_2\": pca_2,\n",
        "    \"pca_3\": pca_3,\n",
        "    \"pca_4\": pca_4,\n",
        "    \"pca_5\": pca_5,\n",
        "    \"pca_6\": pca_6\n",
        "}\n",
        "\n",
        "# Resultados do k-fold\n",
        "kfold_results = []"
      ],
      "metadata": {
        "id": "IOgZy8x3KKi1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop pelos datasets\n",
        "for name, data in datasets.items():\n",
        "    # Separando atributos e rótulos\n",
        "    X = data.iloc[:, :-1].values\n",
        "    y = data.iloc[:, -1].values\n",
        "\n",
        "    # Configurando o KFold\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "    # Testando diferentes valores de max_depth\n",
        "    for max_depth in range(2, 11):\n",
        "        fold_accuracies = []\n",
        "\n",
        "        # Validação cruzada\n",
        "        for train_index, test_index in kf.split(X):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            # Criando e treinando o modelo\n",
        "            model = DecisionTreeClassifier(max_depth=max_depth, random_state=1)\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Prevendo no conjunto de teste\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            # Calculando a acurácia do fold\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            fold_accuracies.append(acc)\n",
        "\n",
        "        # Calculando a média das acurácias dos folds\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "\n",
        "        # Salvando os resultados\n",
        "        kfold_results.append({\"Dataset\": name, \"Max Depth\": max_depth, \"Mean Accuracy\": mean_acc})\n",
        "\n",
        "# Convertendo os resultados para DataFrame\n",
        "kfold_results_df = pd.DataFrame(kfold_results)\n",
        "\n",
        "# Salvando resultado em CSV\n",
        "kfold_results_df.to_csv(\"Resultados_Decision_Tree_Kfold.csv\", index=False)\n",
        "\n",
        "# Visualizando os resultados\n",
        "print(kfold_results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyFfU2JaKN-L",
        "outputId": "a63ecb3a-b365-496d-fb9f-583a811f3c9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Dataset  Max Depth  Mean Accuracy\n",
            "0    vgg16_1          2        0.67375\n",
            "1    vgg16_1          3        0.67250\n",
            "2    vgg16_1          4        0.68625\n",
            "3    vgg16_1          5        0.65625\n",
            "4    vgg16_1          6        0.67250\n",
            "..       ...        ...            ...\n",
            "103    pca_6          6        0.66250\n",
            "104    pca_6          7        0.64125\n",
            "105    pca_6          8        0.64125\n",
            "106    pca_6          9        0.62750\n",
            "107    pca_6         10        0.62750\n",
            "\n",
            "[108 rows x 3 columns]\n"
          ]
        }
      ]
    }
  ]
}