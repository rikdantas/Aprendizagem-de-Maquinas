{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP66+40KiJP9WmJoLbTevQb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rikdantas/Aprendizagem-de-Maquinas/blob/main/ECT3695/Unidade_2/Projeto_U2/Projeto_U2_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabalho: Aplicação de IA e Visão Computacional\n",
        "## Aluno: Paulo Ricardo Dantas\n",
        "## Objetivo\n",
        "Aplicar técnicas de IA e Visão Computacional para resolver um problema prático usando segmentação, detecção, classificação de imagens ou estimativa de pose. Utilizar YOLO ou abordagem similar.\n",
        "\n",
        "Para esse trabalho, iremos escolher o tema de classificação de imagens e iremos usar um dataset que contém imagens de gatos, cachorros e raposas. Iremos treinar um modelo para receber uma imagem de um desses animais e classificar entre essas 3 classes.\n",
        "\n",
        "Esse dataset foi escolhido por ser um dataset de tamanho suficientemente bom para realizar essa atividade.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wg-CsoaUnMdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando o dataset\n",
        "Para realizar o trabalho, iremos usar o dataset \"Animal Image Dataset - Cats, Dogs, and Foxes\" do kaggle que pode ser encontrado no link: <https://www.kaggle.com/datasets/snmahsa/animal-image-dataset-cats-dogs-and-foxes>.\n",
        "\n",
        "Como no projeto é necessário que sejam feitas algumas etapas de pré-processamento, será utilizado o roboflow para auxiliar nessa etapa. Com isso o nosso dataset já vai vir pré-processado."
      ],
      "metadata": {
        "id": "tzReRCVAnmHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pré-processamento\n",
        "Nesse tópico serão descritos as etapas de pré-processamento que foram aplicados ao dataset original:\n",
        "- Divisão de treinamento, validação e teste\n",
        "\n",
        "O dataset foi dividido em 70% para treinamento, 20% para validação e 10% para teste.\n",
        "- Auto-orientação\n",
        "\n",
        "Nessa etapa o próprio roboflow identifica a orientação da imagem e faz o ajuste se necessário.\n",
        "\n",
        "- Redimensionamento\n",
        "\n",
        "As imagens foram redimensionadas para 512 x 512 pixels.\n",
        "\n",
        "- Aumento dos dados\n",
        "\n",
        "Nessa etapa, também usamos o roboflow para adicionar uma rotação entre -15 e 15 graus, saturação entre -25% e 25% e as imagens foram aumentadas em 3 vezes.\n"
      ],
      "metadata": {
        "id": "cxXMcl1tYYM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baixando o dataset"
      ],
      "metadata": {
        "id": "tKHga02DYs1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando o dataset\n",
        "!curl -o roboflow.zip -L \"https://app.roboflow.com/ds/5q7Tm9GJFC?key=qDqmOs8Dij\"\n",
        "\n",
        "# Unzip no dataset\n",
        "!unzip -q roboflow.zip -d dataset\n",
        "\n",
        "# Removendo arquivo baixado\n",
        "!rm roboflow.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYlH-TBIT1mm",
        "outputId": "808d2ef6-2bfa-48f4-ee46-2fe2144b43ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   903  100   903    0     0   2128      0 --:--:-- --:--:-- --:--:--  2129\n",
            "100 24.5M  100 24.5M    0     0  19.4M      0  0:00:01  0:00:01 --:--:-- 53.0M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento\n",
        "Para fazer o treinamento iremos utilizar a rede já treinada do YOLO. Iremos utilizar a versão mais recente de classificação que é a versão:\n",
        " >YOLO11x-cls\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vRvF_-M5cHCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalando a biblioteca da ultralytics"
      ],
      "metadata": {
        "id": "fProUubrc5Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0zbLtd3c4yD",
        "outputId": "cc5dd26c-22f7-4f6d-d423-f25fe783678b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/904.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/904.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m901.1/904.4 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.4/904.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando bibliotecas"
      ],
      "metadata": {
        "id": "EsI1TSJCdEHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVgY92LMdHYM",
        "outputId": "54bcdc8c-cfa0-439b-d20e-e302c1568846"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinando o modelo"
      ],
      "metadata": {
        "id": "Oj90KbPDGtSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando o modelo\n",
        "model = YOLO('yolo11x-cls.pt')\n",
        "\n",
        "# Treinando o modelo\n",
        "model.train(data='/content/dataset', epochs=15, batch=4, imgsz=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjGSEIdxdQbz",
        "outputId": "4661cd9a-fa44-41f4-9e2f-2bfd54a00d0f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-cls.pt to 'yolo11x-cls.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56.9M/56.9M [00:00<00:00, 207MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.56 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11x-cls.pt, data=/content/dataset, epochs=15, time=None, patience=100, batch=4, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/dataset/train... found 648 images in 3 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/dataset/test... found 30 images in 3 classes ✅ \n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
            "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
            "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
            "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
            "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
            "  9                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
            " 10                  -1  1    989443  ultralytics.nn.modules.head.Classify         [768, 3]                      \n",
            "YOLO11x-cls summary: 309 layers, 28,359,907 parameters, 28,359,907 gradients, 111.0 GFLOPs\n",
            "Transferred 492/494 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 67.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train... 648 images, 0 corrupt: 100%|██████████| 648/648 [00:00<00:00, 3828.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/test... 30 images, 0 corrupt: 100%|██████████| 30/30 [00:00<00:00, 10669.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/test.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 512 train, 512 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/15      2.13G      1.168          4        512:   1%|          | 2/162 [00:01<01:23,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/15      2.28G      1.019          4        512:   2%|▏         | 4/162 [00:01<00:47,  3.30it/s]\n",
            "100%|██████████| 755k/755k [00:00<00:00, 16.4MB/s]\n",
            "       1/15      2.29G     0.7412          4        512: 100%|██████████| 162/162 [00:26<00:00,  6.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00,  6.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        0.9          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/15      2.43G     0.2934          4        512: 100%|██████████| 162/162 [00:26<00:00,  6.17it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 11.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        0.9          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/15      2.44G     0.2481          4        512: 100%|██████████| 162/162 [00:25<00:00,  6.40it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 13.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.967          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/15      2.44G     0.1747          4        512: 100%|██████████| 162/162 [00:27<00:00,  5.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 12.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        0.9          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/15      2.43G     0.1941          4        512: 100%|██████████| 162/162 [00:25<00:00,  6.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 11.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.967          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/15      2.43G     0.1752          4        512: 100%|██████████| 162/162 [00:25<00:00,  6.44it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 13.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        0.9          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/15      2.43G     0.1683          4        512: 100%|██████████| 162/162 [00:27<00:00,  5.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 13.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.967          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/15      2.43G     0.1804          4        512: 100%|██████████| 162/162 [00:25<00:00,  6.25it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        0.9          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/15      2.44G     0.1493          4        512: 100%|██████████| 162/162 [00:24<00:00,  6.49it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 14.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.967          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/15      2.43G    0.09519          4        512: 100%|██████████| 162/162 [00:27<00:00,  5.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 14.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.967          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/15      2.43G    0.09997          4        512: 100%|██████████| 162/162 [00:27<00:00,  5.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 10.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.933          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/15      2.43G     0.1073          4        512: 100%|██████████| 162/162 [00:24<00:00,  6.65it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 13.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.933          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/15      2.43G    0.07897          4        512: 100%|██████████| 162/162 [00:26<00:00,  6.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 13.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.967          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/15      2.43G    0.05648          4        512: 100%|██████████| 162/162 [00:25<00:00,  6.23it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 12.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.967          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/15      2.43G     0.0433          4        512: 100%|██████████| 162/162 [00:24<00:00,  6.59it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 12.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.967          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "15 epochs completed in 0.119 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 57.0MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 57.0MB\n",
            "\n",
            "Validating runs/classify/train/weights/best.pt...\n",
            "Ultralytics 8.3.56 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11x-cls summary (fused): 227 layers, 28,336,259 parameters, 0 gradients, 110.3 GFLOPs\n",
            "WARNING ⚠️ Dataset 'split=val' not found, using 'split=test' instead.\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/dataset/train... found 648 images in 3 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/dataset/test... found 30 images in 3 classes ✅ \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.967          1\n",
            "Speed: 0.5ms preprocess, 17.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
              "\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7e96f40ac520>\n",
              "curves: []\n",
              "curves_results: []\n",
              "fitness: 0.9833333194255829\n",
              "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
              "results_dict: {'metrics/accuracy_top1': 0.9666666388511658, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9833333194255829}\n",
              "save_dir: PosixPath('runs/classify/train')\n",
              "speed: {'preprocess': 0.4823843638102214, 'inference': 17.26365884145101, 'loss': 0.0022252400716145835, 'postprocess': 0.0030835469563802085}\n",
              "task: 'classify'\n",
              "top1: 0.9666666388511658\n",
              "top5: 1.0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando o modelo\n",
        "O modelo já foi testado com algumas imagens que foram previamente separadas do dataset original, porém para ilustrar mais um pouco, vão ser baixadas imagens da internet para testar o modelo."
      ],
      "metadata": {
        "id": "vr4NotDyGy6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "# Carregar o modelo treinado\n",
        "model = YOLO('runs/classify/train/weights/best.pt')\n",
        "\n",
        "# Diretório para salvar as imagens baixadas\n",
        "output_dir = 'test_images'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# URLs das imagens e seus novos nomes\n",
        "image_data = [\n",
        "    {\"url\": \"https://www.designi.com.br/images/preview/10094828.jpg\", \"name\": \"cat_test1.jpg\"},\n",
        "    {\"url\": \"https://super.abril.com.br/wp-content/uploads/2024/05/1505-racas-cachorros-super-site.jpg?quality=70&strip=info&w=720&h=440&crop=1\", \"name\": \"cat_test2.jpg\"},\n",
        "    {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/3/30/Vulpes_vulpes_ssp_fulvus.jpg\", \"name\": \"fox_test1.jpg\"},\n",
        "    {\"url\": \"https://animalbusiness.com.br/wp-content/uploads/2022/03/raposa_chaoterra_saviofreire.jpg\", \"name\": \"fox_test2.jpg\"},\n",
        "    {\"url\": \"https://academiawashington.com.br/wp-content/uploads/2017/09/coisas-incriveis-sobre-seu-cachorro.jpg\", \"name\": \"dog_test1.jpg\"},\n",
        "    {\"url\": \"https://c.pxhere.com/photos/e4/aa/dog_look_pet_animal_animals_mammals_puppy_friend-692239.jpg!d\", \"name\": \"dog_test2.jpg\"}\n",
        "]\n",
        "\n",
        "# Baixar e salvar as imagens com os novos nomes\n",
        "saved_images = []\n",
        "for data in image_data:\n",
        "    response = requests.get(data[\"url\"])\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    save_path = os.path.join(output_dir, data[\"name\"])\n",
        "    img.save(save_path)\n",
        "    saved_images.append(save_path)\n",
        "    print(f\"Imagem salva como: {save_path}\")\n",
        "\n",
        "\n",
        "# Fazer a inferência nas imagens salvas\n",
        "for image_path in saved_images:\n",
        "    results = model.predict(source=image_path, task='classify')\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(f\"Resultados para a imagem {image_path}:\")\n",
        "    for result in results:\n",
        "        print(f\"Classe: {result.names[result.probs.top1]}, Confiança: {result.probs.top1conf:.2f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zHjShGjJurP",
        "outputId": "ae8cffc4-d421-48bd-cf17-cf9ef4b4495f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagem salva como: test_images/cat_test1.jpg\n",
            "Imagem salva como: test_images/cat_test2.jpg\n",
            "Imagem salva como: test_images/fox_test1.jpg\n",
            "Imagem salva como: test_images/fox_test2.jpg\n",
            "Imagem salva como: test_images/dog_test1.jpg\n",
            "Imagem salva como: test_images/dog_test2.jpg\n",
            "\n",
            "image 1/1 /content/test_images/cat_test1.jpg: 512x512 cat 1.00, fox 0.00, dog 0.00, 36.4ms\n",
            "Speed: 24.8ms preprocess, 36.4ms inference, 0.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "Resultados para a imagem test_images/cat_test1.jpg:\n",
            "Classe: cat, Confiança: 1.00\n",
            "--------------------------------------------------\n",
            "\n",
            "image 1/1 /content/test_images/cat_test2.jpg: 512x512 cat 1.00, dog 0.00, fox 0.00, 35.0ms\n",
            "Speed: 18.4ms preprocess, 35.0ms inference, 0.2ms postprocess per image at shape (1, 3, 512, 512)\n",
            "Resultados para a imagem test_images/cat_test2.jpg:\n",
            "Classe: cat, Confiança: 1.00\n",
            "--------------------------------------------------\n",
            "\n",
            "image 1/1 /content/test_images/fox_test1.jpg: 512x512 fox 1.00, dog 0.00, cat 0.00, 34.2ms\n",
            "Speed: 34.0ms preprocess, 34.2ms inference, 0.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "Resultados para a imagem test_images/fox_test1.jpg:\n",
            "Classe: fox, Confiança: 1.00\n",
            "--------------------------------------------------\n",
            "\n",
            "image 1/1 /content/test_images/fox_test2.jpg: 512x512 fox 0.59, cat 0.35, dog 0.06, 34.1ms\n",
            "Speed: 17.5ms preprocess, 34.1ms inference, 0.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "Resultados para a imagem test_images/fox_test2.jpg:\n",
            "Classe: fox, Confiança: 0.59\n",
            "--------------------------------------------------\n",
            "\n",
            "image 1/1 /content/test_images/dog_test1.jpg: 512x512 dog 1.00, fox 0.00, cat 0.00, 29.4ms\n",
            "Speed: 24.2ms preprocess, 29.4ms inference, 0.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "Resultados para a imagem test_images/dog_test1.jpg:\n",
            "Classe: dog, Confiança: 1.00\n",
            "--------------------------------------------------\n",
            "\n",
            "image 1/1 /content/test_images/dog_test2.jpg: 512x512 dog 0.99, cat 0.01, fox 0.00, 29.4ms\n",
            "Speed: 27.4ms preprocess, 29.4ms inference, 0.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "Resultados para a imagem test_images/dog_test2.jpg:\n",
            "Classe: dog, Confiança: 0.99\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}